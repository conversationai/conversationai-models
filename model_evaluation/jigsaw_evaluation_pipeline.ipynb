{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YibCLoSLRHp"
   },
   "source": [
    "Copyright 2018 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMykUGMauh9b"
   },
   "source": [
    "# Evaluation code\n",
    "\n",
    "\n",
    "__Disclaimer__\n",
    "*   This notebook contains experimental code, which may be changed without notice.\n",
    "*   The ideas here are some ideas relevant to fairness - they are not the whole story!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook intends to evaluate a list of models on two dimensions:\n",
    "- \"Performance\": How well the model perform to classify the data (intended bias). Currently, we use the AUC.\n",
    "- \"Bias\": How much bias does the model contain (unintended bias). Currently, we use the pinned auc.\n",
    "\n",
    "This script takes the following steps:\n",
    "\n",
    "- Defines the models to evaluate and specify their signature (expected inputs/outputs).\n",
    "- Write input function to generate 2 datasets:\n",
    "    - A \"performance dataset\" which will be used for the first set of metrics. This dataset is supposed to be similar format to the training data (contain a piece of text and a label).\n",
    "    - A \"bias dataset\" which will be used for the second set of metrics. This data contains a piece of text, a label but also some subgroup information to evaluate the unintended bias on.\n",
    "- Runs predictions with the export_utils.\n",
    "- Evaluate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import getpass\n",
    "from IPython.display import display\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import auth\n",
    "#auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U -q git+https://github.com/conversationai/unintended-ml-bias-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unintended_ml_bias import model_bias_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import input_fn_example\n",
    "from utils_export.dataset import Dataset, Model\n",
    "from utils_export import utils_cloudml\n",
    "from utils_export import utils_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GCS_READ_CACHE_MAX_SIZE_MB'] = '0' #Faster to access GCS file + https://github.com/tensorflow/tensorflow/issues/15530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nthain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "PROJECT_NAME = 'conversationai-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Defining your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important user input is the description of the deployed models that are evaluated.\n",
    "\n",
    "1- Defining which model will be used.\n",
    "$MODEL_NAMES defined the different names (format: \"model_name:version\").\n",
    "\n",
    "2- Defining the model signature.\n",
    "Currently, the `Dataset` API does not detect the signature of a CMLE model, so this information is given by a `Model` instance.\n",
    "You need to describe:\n",
    "- input_spec: what the input_file should be (argument `feature_keys_spec`). It is a dictionary which describes the name of the fields and their types.\n",
    "- prediction_keys (argument `prediction_keys`). It is the name of the prediction field in the model output.\n",
    "- Name of the example key (argument `example_key`). A unique identifier for each sentence which will be generated by the dataset API (a.k.a. your input data does not need to have this field).\n",
    "    - When using Cloud MLE for batch predictions, data is processed in an unpredictable order. To be able to match the returned predictions with your input instances, you must have instance keys defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs:\n",
    "MODEL_NAMES = [\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738', # ??\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748', # ??\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820', # ??\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828', # ??\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs: Model description (see above for more info).\n",
    "TEXT_FEATURE_NAME = 'tokens' #Input defined in serving function called in run.py (arg: `text_feature_name`).\n",
    "SENTENCE_KEY = 'comment_key' #Input key defined in serving functioncalled in run.py (arg: `example_key_name`).\n",
    "#LABEL_NAME_PREDICTION_MODEL = 'scores' # Output prediction: typically $label_name/logistic\n",
    "LABEL_NAME_PREDICTION_MODEL = 'probabilities' # Output prediction: typically $label_name/logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_spec = {\n",
    "    TEXT_FEATURE_NAME: utils_tfrecords.EncodingFeatureSpec.LIST_STRING} #library will use this automatically\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Defining the input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text, lowercase=True):\n",
    "  \"\"\"Converts text to a list of words.\n",
    "\n",
    "  Args:\n",
    "    text: piece of text to tokenize (string).\n",
    "    lowercase: whether to include lowercasing in preprocessing (boolean).\n",
    "    tokenizer: Python function to tokenize the text on.\n",
    "\n",
    "  Returns:\n",
    "    A list of strings (words).\n",
    "  \"\"\"\n",
    "  words = nltk.word_tokenize(text.decode('utf-8'))\n",
    "  if lowercase:\n",
    "    words = [w.lower() for w in words]\n",
    "  return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define first some input_fn which will be fed to the `Dataset` API.\n",
    "An input_fn must follow the following requirements:\n",
    "- Returns a pandas DataFrame\n",
    "- Have an argument 'max_n_examples' to control the size of the dataframe.\n",
    "- Containing at least a field $TEXT_FEATURE_NAME, which maps to a tokenized text (list of words) AND  a field 'label' which is 1 for toxic (0 otherwise).\n",
    "\n",
    "We will define two different input_fn (1 for performance, 1 for bias). The bias input_fn should also contain identity information.\n",
    "\n",
    "Note: You can use ANY input_fn that matches those requirements. You can find a few examples of input_fn in the file input_fn_example.py (for toxicity and civil_comments dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs: Choose which one you want to use OR create your own!\n",
    "INPUT_FN_PERFORMANCE = input_fn_example.create_input_fn_biasbios(\n",
    "    tokenizer,\n",
    "    model_input_comment_field=TEXT_FEATURE_NAME,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Running prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "SIZE_PERFORMANCE_DATA_SET = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://conversationai-models/nthain/tfrecords/performance_dataset_dir\n"
     ]
    }
   ],
   "source": [
    "# Pattern for path of tf_records\n",
    "PERFORMANCE_DATASET_DIR = os.path.join(\n",
    "    'gs://conversationai-models/',\n",
    "    getpass.getuser(),\n",
    "    'tfrecords',\n",
    "    'performance_dataset_dir')\n",
    "print(PERFORMANCE_DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_fn is compatible with the `Dataset` class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nthain/Documents/repos/conversationai-models/model_evaluation/.venv/lib/python2.7/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "dataset_performance = Dataset(INPUT_FN_PERFORMANCE, PERFORMANCE_DATASET_DIR)\n",
    "random.seed(2018) # Need to set seed before loading data to be able to reload same data in the future\n",
    "dataset_performance.load_data(SIZE_PERFORMANCE_DATA_SET, random_filter_keep_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, her, role, ,, she, is, a, member, of, an,...</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[his, blog, www.donaldhtaylorjr.blogspot.com, ...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[he, has, primarily, reported, for, the, atlan...</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[andrea, 's, area, of, expertise, is, in, whol...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dr., milane, was, trained, as, a, national, c...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[he, is, also, visiting, associate, professor,...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[her, research, focuses, on, the, trafficking,...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[he, has, been, licensed, to, practice, law, i...</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[after, a, two-year, postdoctoral, fellowship,...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[prior, to, teaching, ,, she, was, an, account...</td>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[jackie, 's, works, are, published, in, academ...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[her, research, topic, was, the, investigation...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[she, graduated, with, honors, in, 2012, ., ha...</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[his, research, focuses, on, the, japan, air, ...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[she, directed, the, 2014, peabody, award-winn...</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[he, lends, his, exceptional, surgical, skills...</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[he, teaches, courses, ranging, from, core, un...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[her, major, fields, of, interest, are, develo...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[dr., cole, honors, several, insurance, carrie...</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[she, practices, in, the, areas, of, business,...</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[she, has, obtained, her, phd, in, eu, law, fr...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[his, photographs, are, reminiscent, of, silho...</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[he, earned, his, ph.d., at, the, university, ...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[his, inter-, disciplinary, research, interest...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[she, earned, her, ph.d., in, communication, s...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[his, current, projects, examine, intergenerat...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[he, has, served, as, an, expert, witness, in,...</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[she, 's, called, in, some, of, the, parent, o...</td>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[nneka, has, recently, become, interested, in,...</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[she, writes, regularly, for, faith, and, lead...</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>[he, was, previously, an, assistant, professor...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>[aside, from, filmmaking, ,, he, ’, s, an, avi...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>[he, lives, in, dallas, with, his, wife, and, ...</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>[he, exhibited, in, institutions, like, kultur...</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>[he, has, represented, numerous, municipalitie...</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>[his, works, include, portrait, ,, glamour, an...</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>[he, began, using, haskell, during, his, senio...</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>[he, has, been, involved, with, streaming, med...</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>[he, has, also, produced, lecture, courses, fo...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>[after, completing, her, degrees, at, the, uni...</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>[this, is, a, slightly, edited, version, of, h...</td>\n",
       "      <td>F</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>[she, received, her, b.sc, ., in, nutrition, f...</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>[she, is, the, author, of, pelo, bueno, y, otr...</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>[she, obtained, her, bachelor, of, science, de...</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>[dr., kanchan, singh, practices, at, singh, de...</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>[prior, to, joining, fresh, 'n, fit, cuisine, ...</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>[he, worked, on, staff, at, aopa, pilot, magaz...</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>[he, started, working, on, these, themes, duri...</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>[his, research, aims, to, understand, the, con...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>[he, received, the, ph.d., degree, in, measuri...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>[he, currently, practices, at, johns, hopkins,...</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>[she, received, her, m.a, ., in, secondary, ed...</td>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>[his, research, interests, lie, in, the, study...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>[she, graduated, with, honors, in, 2000, ., ha...</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>[chris, primarily, teaches, anatomy, and, phys...</td>\n",
       "      <td>M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[always, responsive, to, the, specific, geogra...</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[he, has, worked, on, numerous, projects, that...</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[he, graduated, from, the, academy, of, visual...</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[most, of, his, writing, is, from, the, middle...</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[he, is, currently, on, the, good, news, poetr...</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens gender  label\n",
       "0     [in, her, role, ,, she, is, a, member, of, an,...      F     17\n",
       "1     [his, blog, www.donaldhtaylorjr.blogspot.com, ...      M     25\n",
       "2     [he, has, primarily, reported, for, the, atlan...      M     12\n",
       "3     [andrea, 's, area, of, expertise, is, in, whol...      F     25\n",
       "4     [dr., milane, was, trained, as, a, national, c...      F     25\n",
       "5     [he, is, also, visiting, associate, professor,...      M     25\n",
       "6     [her, research, focuses, on, the, trafficking,...      F     25\n",
       "7     [he, has, been, licensed, to, practice, law, i...      M      3\n",
       "8     [after, a, two-year, postdoctoral, fellowship,...      M     25\n",
       "9     [prior, to, teaching, ,, she, was, an, account...      F     31\n",
       "10    [jackie, 's, works, are, published, in, academ...      F     25\n",
       "11    [her, research, topic, was, the, investigation...      F     25\n",
       "12    [she, graduated, with, honors, in, 2012, ., ha...      F     17\n",
       "13    [his, research, focuses, on, the, japan, air, ...      M     25\n",
       "14    [she, directed, the, 2014, peabody, award-winn...      F     10\n",
       "15    [he, lends, his, exceptional, surgical, skills...      M     30\n",
       "16    [he, teaches, courses, ranging, from, core, un...      M     25\n",
       "17    [her, major, fields, of, interest, are, develo...      F     25\n",
       "18    [dr., cole, honors, several, insurance, carrie...      M     23\n",
       "19    [she, practices, in, the, areas, of, business,...      F      3\n",
       "20    [she, has, obtained, her, phd, in, eu, law, fr...      F     25\n",
       "21    [his, photographs, are, reminiscent, of, silho...      M     22\n",
       "22    [he, earned, his, ph.d., at, the, university, ...      M     25\n",
       "23    [his, inter-, disciplinary, research, interest...      M     25\n",
       "24    [she, earned, her, ph.d., in, communication, s...      F     25\n",
       "25    [his, current, projects, examine, intergenerat...      M     25\n",
       "26    [he, has, served, as, an, expert, witness, in,...      M      0\n",
       "27    [she, 's, called, in, some, of, the, parent, o...      F     31\n",
       "28    [nneka, has, recently, become, interested, in,...      F      3\n",
       "29    [she, writes, regularly, for, faith, and, lead...      F     20\n",
       "...                                                 ...    ...    ...\n",
       "9970  [he, was, previously, an, assistant, professor...      M     25\n",
       "9971  [aside, from, filmmaking, ,, he, ’, s, an, avi...      M     10\n",
       "9972  [he, lives, in, dallas, with, his, wife, and, ...      M     29\n",
       "9973  [he, exhibited, in, institutions, like, kultur...      M     22\n",
       "9974  [he, has, represented, numerous, municipalitie...      M      3\n",
       "9975  [his, works, include, portrait, ,, glamour, an...      M     22\n",
       "9976  [he, began, using, haskell, during, his, senio...      M     29\n",
       "9977  [he, has, been, involved, with, streaming, med...      M      2\n",
       "9978  [he, has, also, produced, lecture, courses, fo...      M     25\n",
       "9979  [after, completing, her, degrees, at, the, uni...      F     23\n",
       "9980  [this, is, a, slightly, edited, version, of, h...      F     12\n",
       "9981  [she, received, her, b.sc, ., in, nutrition, f...      F      8\n",
       "9982  [she, is, the, author, of, pelo, bueno, y, otr...      F     24\n",
       "9983  [she, obtained, her, bachelor, of, science, de...      F     23\n",
       "9984  [dr., kanchan, singh, practices, at, singh, de...      M     30\n",
       "9985  [prior, to, joining, fresh, 'n, fit, cuisine, ...      F      8\n",
       "9986  [he, worked, on, staff, at, aopa, pilot, magaz...      M     12\n",
       "9987  [he, started, working, on, these, themes, duri...      M     18\n",
       "9988  [his, research, aims, to, understand, the, con...      M     25\n",
       "9989  [he, received, the, ph.d., degree, in, measuri...      M     25\n",
       "9990  [he, currently, practices, at, johns, hopkins,...      M     30\n",
       "9991  [she, received, her, m.a, ., in, secondary, ed...      F     31\n",
       "9992  [his, research, interests, lie, in, the, study...      M     25\n",
       "9993  [she, graduated, with, honors, in, 2000, ., ha...      F     26\n",
       "9994  [chris, primarily, teaches, anatomy, and, phys...      M     31\n",
       "9995  [always, responsive, to, the, specific, geogra...      F      2\n",
       "9996  [he, has, worked, on, numerous, projects, that...      M     29\n",
       "9997  [he, graduated, from, the, academy, of, visual...      M     22\n",
       "9998  [most, of, his, writing, is, from, the, middle...      M     12\n",
       "9999  [he, is, currently, on, the, good, news, poetr...      M     24\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_performance.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_performance.show_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'tokens', u'gender', u'label'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_performance.show_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = range(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"comment_text\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \" In her role, she is a member of an innovative team-based care model which has been recognized by Wall Street Journal and the Robert Wood Johnson Foundation. A process improvement leader with a passion for serving vulnerable populations, Amberly was recognized by her colleagues with the first Daisy Award for Extraordinary Nurses at Cambridge Health Alliance. Amberly holds a BS in Nursing from Valparaiso University and a Masters in Public Health from the University of Massachusetts Amherst. read more\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"gender\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"F\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"title\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 17\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INPUT_DATA = 'gs://conversationai-models/biosbias/dataflow_dir/data-preparation-20190220165938/eval-00000-of-00003.tfrecord'\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=INPUT_DATA)\n",
    "string_record = next(record_iterator)\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(string_record)\n",
    "text = example.features.feature\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Model is compatible with the `Dataset` instance.\n",
      "WARNING:tensorflow:Using past predictions. the data must match exactly (same number of lines and same order).\n"
     ]
    }
   ],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "dataset_performance.add_model_prediction_to_data(model, recompute_predictions=False, class_names=CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://conversationai-models/nthain/tfrecords/performance_dataset_dir/prediction_data_tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "def _load_predictions(pred_file):\n",
    "    with file_io.FileIO(pred_file, 'r') as f:\n",
    "      # prediction file needs to fit in memory.\n",
    "      try:\n",
    "        predictions = [json.loads(line) for line in f]\n",
    "      except:\n",
    "        predictions = []\n",
    "    return predictions\n",
    "\n",
    "model_name_tmp = MODEL_NAMES[0]\n",
    "prediction_file = dataset_performance.get_path_prediction(model_name_tmp)\n",
    "print(prediction_file)\n",
    "prediction_file = os.path.join(prediction_file,\n",
    "                                 'prediction.results-00000-of-00001')\n",
    "print(len(_load_predictions(prediction_file)[0]['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance_df = dataset_performance.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bias_df = test_performance_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1530641283264,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "Y7R4heIB5GaV",
    "outputId": "e8e0c3bc-96d8-4635-865a-275052054df8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_0</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_1</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_2</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_3</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_4</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_5</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_23</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_24</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_25</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_26</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_27</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_28</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_29</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_30</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_31</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, her, role, ,, she, is, a, member, of, an,...</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>1.814099e-11</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.009853</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>4.412969e-04</td>\n",
       "      <td>6.086852e-17</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[his, blog, www.donaldhtaylorjr.blogspot.com, ...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>2.716771e-13</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.022347</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>9.439933e-07</td>\n",
       "      <td>5.250679e-18</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[he, has, primarily, reported, for, the, atlan...</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>8.870694e-16</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.029823</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.022292</td>\n",
       "      <td>0.077598</td>\n",
       "      <td>0.033979</td>\n",
       "      <td>8.196229e-05</td>\n",
       "      <td>3.315851e-11</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[andrea, 's, area, of, expertise, is, in, whol...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>1.019689e-15</td>\n",
       "      <td>0.017150</td>\n",
       "      <td>0.052085</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.052322</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.145462</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>3.909138e-04</td>\n",
       "      <td>1.304484e-21</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dr., milane, was, trained, as, a, national, c...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>1.783027e-12</td>\n",
       "      <td>0.196227</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.220090</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>7.920414e-05</td>\n",
       "      <td>2.406181e-13</td>\n",
       "      <td>0.150817</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>0.071632</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens gender  label  \\\n",
       "0  [in, her, role, ,, she, is, a, member, of, an,...      F     17   \n",
       "1  [his, blog, www.donaldhtaylorjr.blogspot.com, ...      M     25   \n",
       "2  [he, has, primarily, reported, for, the, atlan...      M     12   \n",
       "3  [andrea, 's, area, of, expertise, is, in, whol...      F     25   \n",
       "4  [dr., milane, was, trained, as, a, national, c...      F     25   \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_0  \\\n",
       "0                                           0.001687                           \n",
       "1                                           0.014774                           \n",
       "2                                           0.016779                           \n",
       "3                                           0.017742                           \n",
       "4                                           0.015531                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_1  \\\n",
       "0                                       1.814099e-11                           \n",
       "1                                       2.716771e-13                           \n",
       "2                                       8.870694e-16                           \n",
       "3                                       1.019689e-15                           \n",
       "4                                       1.783027e-12                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_2  \\\n",
       "0                                           0.002681                           \n",
       "1                                           0.005496                           \n",
       "2                                           0.001688                           \n",
       "3                                           0.017150                           \n",
       "4                                           0.196227                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_3  \\\n",
       "0                                           0.009853                           \n",
       "1                                           0.022347                           \n",
       "2                                           0.071343                           \n",
       "3                                           0.052085                           \n",
       "4                                           0.016471                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_4  \\\n",
       "0                                           0.004227                           \n",
       "1                                           0.003845                           \n",
       "2                                           0.000560                           \n",
       "3                                           0.002097                           \n",
       "4                                           0.002690                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_5  \\\n",
       "0                                           0.055716                           \n",
       "1                                           0.084480                           \n",
       "2                                           0.029823                           \n",
       "3                                           0.052322                           \n",
       "4                                           0.000040                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_6  \\\n",
       "0                                           0.003005                           \n",
       "1                                           0.000096                           \n",
       "2                                           0.000032                           \n",
       "3                                           0.002627                           \n",
       "4                                           0.001384                           \n",
       "\n",
       "                                      ...                                      \\\n",
       "0                                     ...                                       \n",
       "1                                     ...                                       \n",
       "2                                     ...                                       \n",
       "3                                     ...                                       \n",
       "4                                     ...                                       \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_23  \\\n",
       "0                                           0.003351                            \n",
       "1                                           0.010309                            \n",
       "2                                           0.018767                            \n",
       "3                                           0.001580                            \n",
       "4                                           0.013445                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_24  \\\n",
       "0                                           0.013561                            \n",
       "1                                           0.001055                            \n",
       "2                                           0.022292                            \n",
       "3                                           0.145462                            \n",
       "4                                           0.003754                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_25  \\\n",
       "0                                           0.002040                            \n",
       "1                                           0.001062                            \n",
       "2                                           0.077598                            \n",
       "3                                           0.000637                            \n",
       "4                                           0.220090                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_26  \\\n",
       "0                                           0.001682                            \n",
       "1                                           0.006205                            \n",
       "2                                           0.033979                            \n",
       "3                                           0.000337                            \n",
       "4                                           0.081232                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_27  \\\n",
       "0                                       4.412969e-04                            \n",
       "1                                       9.439933e-07                            \n",
       "2                                       8.196229e-05                            \n",
       "3                                       3.909138e-04                            \n",
       "4                                       7.920414e-05                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_28  \\\n",
       "0                                       6.086852e-17                            \n",
       "1                                       5.250679e-18                            \n",
       "2                                       3.315851e-11                            \n",
       "3                                       1.304484e-21                            \n",
       "4                                       2.406181e-13                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_29  \\\n",
       "0                                           0.001606                            \n",
       "1                                           0.001204                            \n",
       "2                                           0.007313                            \n",
       "3                                           0.011515                            \n",
       "4                                           0.150817                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_30  \\\n",
       "0                                           0.001379                            \n",
       "1                                           0.000150                            \n",
       "2                                           0.002565                            \n",
       "3                                           0.000922                            \n",
       "4                                           0.014913                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_31  \\\n",
       "0                                           0.014635                            \n",
       "1                                           0.015252                            \n",
       "2                                           0.118167                            \n",
       "3                                           0.029867                            \n",
       "4                                           0.071632                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_32  \n",
       "0                                           0.000032                           \n",
       "1                                           0.000779                           \n",
       "2                                           0.001603                           \n",
       "3                                           0.000001                           \n",
       "4                                           0.000142                           \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1530641286091,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "Ln2BXOg4Q6GP",
    "outputId": "bb5288e8-9f10-4796-b36e-42f5c02cb148"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_0</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_1</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_2</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_3</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_4</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_5</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_23</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_24</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_25</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_26</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_27</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_28</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_29</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_30</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_31</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, her, role, ,, she, is, a, member, of, an,...</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>1.814099e-11</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.009853</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>4.412969e-04</td>\n",
       "      <td>6.086852e-17</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[his, blog, www.donaldhtaylorjr.blogspot.com, ...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>2.716771e-13</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.022347</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>9.439933e-07</td>\n",
       "      <td>5.250679e-18</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[he, has, primarily, reported, for, the, atlan...</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>8.870694e-16</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.029823</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.022292</td>\n",
       "      <td>0.077598</td>\n",
       "      <td>0.033979</td>\n",
       "      <td>8.196229e-05</td>\n",
       "      <td>3.315851e-11</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[andrea, 's, area, of, expertise, is, in, whol...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>1.019689e-15</td>\n",
       "      <td>0.017150</td>\n",
       "      <td>0.052085</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.052322</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.145462</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>3.909138e-04</td>\n",
       "      <td>1.304484e-21</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dr., milane, was, trained, as, a, national, c...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>1.783027e-12</td>\n",
       "      <td>0.196227</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.220090</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>7.920414e-05</td>\n",
       "      <td>2.406181e-13</td>\n",
       "      <td>0.150817</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>0.071632</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens gender  label  \\\n",
       "0  [in, her, role, ,, she, is, a, member, of, an,...      F     17   \n",
       "1  [his, blog, www.donaldhtaylorjr.blogspot.com, ...      M     25   \n",
       "2  [he, has, primarily, reported, for, the, atlan...      M     12   \n",
       "3  [andrea, 's, area, of, expertise, is, in, whol...      F     25   \n",
       "4  [dr., milane, was, trained, as, a, national, c...      F     25   \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_0  \\\n",
       "0                                           0.001687                           \n",
       "1                                           0.014774                           \n",
       "2                                           0.016779                           \n",
       "3                                           0.017742                           \n",
       "4                                           0.015531                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_1  \\\n",
       "0                                       1.814099e-11                           \n",
       "1                                       2.716771e-13                           \n",
       "2                                       8.870694e-16                           \n",
       "3                                       1.019689e-15                           \n",
       "4                                       1.783027e-12                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_2  \\\n",
       "0                                           0.002681                           \n",
       "1                                           0.005496                           \n",
       "2                                           0.001688                           \n",
       "3                                           0.017150                           \n",
       "4                                           0.196227                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_3  \\\n",
       "0                                           0.009853                           \n",
       "1                                           0.022347                           \n",
       "2                                           0.071343                           \n",
       "3                                           0.052085                           \n",
       "4                                           0.016471                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_4  \\\n",
       "0                                           0.004227                           \n",
       "1                                           0.003845                           \n",
       "2                                           0.000560                           \n",
       "3                                           0.002097                           \n",
       "4                                           0.002690                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_5  \\\n",
       "0                                           0.055716                           \n",
       "1                                           0.084480                           \n",
       "2                                           0.029823                           \n",
       "3                                           0.052322                           \n",
       "4                                           0.000040                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_6  \\\n",
       "0                                           0.003005                           \n",
       "1                                           0.000096                           \n",
       "2                                           0.000032                           \n",
       "3                                           0.002627                           \n",
       "4                                           0.001384                           \n",
       "\n",
       "                                      ...                                      \\\n",
       "0                                     ...                                       \n",
       "1                                     ...                                       \n",
       "2                                     ...                                       \n",
       "3                                     ...                                       \n",
       "4                                     ...                                       \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_23  \\\n",
       "0                                           0.003351                            \n",
       "1                                           0.010309                            \n",
       "2                                           0.018767                            \n",
       "3                                           0.001580                            \n",
       "4                                           0.013445                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_24  \\\n",
       "0                                           0.013561                            \n",
       "1                                           0.001055                            \n",
       "2                                           0.022292                            \n",
       "3                                           0.145462                            \n",
       "4                                           0.003754                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_25  \\\n",
       "0                                           0.002040                            \n",
       "1                                           0.001062                            \n",
       "2                                           0.077598                            \n",
       "3                                           0.000637                            \n",
       "4                                           0.220090                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_26  \\\n",
       "0                                           0.001682                            \n",
       "1                                           0.006205                            \n",
       "2                                           0.033979                            \n",
       "3                                           0.000337                            \n",
       "4                                           0.081232                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_27  \\\n",
       "0                                       4.412969e-04                            \n",
       "1                                       9.439933e-07                            \n",
       "2                                       8.196229e-05                            \n",
       "3                                       3.909138e-04                            \n",
       "4                                       7.920414e-05                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_28  \\\n",
       "0                                       6.086852e-17                            \n",
       "1                                       5.250679e-18                            \n",
       "2                                       3.315851e-11                            \n",
       "3                                       1.304484e-21                            \n",
       "4                                       2.406181e-13                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_29  \\\n",
       "0                                           0.001606                            \n",
       "1                                           0.001204                            \n",
       "2                                           0.007313                            \n",
       "3                                           0.011515                            \n",
       "4                                           0.150817                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_30  \\\n",
       "0                                           0.001379                            \n",
       "1                                           0.000150                            \n",
       "2                                           0.002565                            \n",
       "3                                           0.000922                            \n",
       "4                                           0.014913                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_31  \\\n",
       "0                                           0.014635                            \n",
       "1                                           0.015252                            \n",
       "2                                           0.118167                            \n",
       "3                                           0.029867                            \n",
       "4                                           0.071632                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828_32  \n",
       "0                                           0.000032                           \n",
       "1                                           0.000779                           \n",
       "2                                           0.001603                           \n",
       "3                                           0.000001                           \n",
       "4                                           0.000142                           \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8m8QI4qEjtcY"
   },
   "source": [
    "# Part 4: Run evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhwSHsMtO9fF"
   },
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our performance data is in DataFrame df, with columns:\n",
    "\n",
    "- label: True if the comment is Toxic, False otherwise.\n",
    "- < model name >: One column per model, cells contain the score from that model.\n",
    "You can run the analysis below on any data in this format. Subgroup labels can be generated via words in the text as done above, or come from human labels if you have them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XUZYCq-6N8MK"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    3295\n",
       "3      890\n",
       "22     661\n",
       "12     542\n",
       "26     507\n",
       "23     494\n",
       "17     481\n",
       "31     427\n",
       "30     343\n",
       "7      268\n",
       "2      265\n",
       "18     209\n",
       "16     202\n",
       "24     197\n",
       "29     194\n",
       "10     185\n",
       "6      156\n",
       "0      141\n",
       "8      102\n",
       "5       87\n",
       "20      67\n",
       "4       58\n",
       "32      50\n",
       "19      41\n",
       "9       39\n",
       "11      37\n",
       "27      32\n",
       "21      30\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7        True\n",
       "8       False\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12      False\n",
       "13      False\n",
       "14      False\n",
       "15      False\n",
       "16      False\n",
       "17      False\n",
       "18      False\n",
       "19       True\n",
       "20      False\n",
       "21      False\n",
       "22      False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "26      False\n",
       "27      False\n",
       "28       True\n",
       "29      False\n",
       "        ...  \n",
       "9970    False\n",
       "9971    False\n",
       "9972    False\n",
       "9973    False\n",
       "9974     True\n",
       "9975    False\n",
       "9976    False\n",
       "9977    False\n",
       "9978    False\n",
       "9979    False\n",
       "9980    False\n",
       "9981    False\n",
       "9982    False\n",
       "9983    False\n",
       "9984    False\n",
       "9985    False\n",
       "9986    False\n",
       "9987    False\n",
       "9988    False\n",
       "9989    False\n",
       "9990    False\n",
       "9991    False\n",
       "9992    False\n",
       "9993    False\n",
       "9994    False\n",
       "9995    False\n",
       "9996    False\n",
       "9997    False\n",
       "9998    False\n",
       "9999    False\n",
       "Name: label, Length: 10000, dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_df['label'] == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.009853\n",
       "1       0.022347\n",
       "2       0.071343\n",
       "3       0.052085\n",
       "4       0.016471\n",
       "5       0.101164\n",
       "6       0.011855\n",
       "7       0.001939\n",
       "8       0.577954\n",
       "9       0.128116\n",
       "10      0.014246\n",
       "11      0.022629\n",
       "12      0.050127\n",
       "13      0.205395\n",
       "14      0.038603\n",
       "15      0.045960\n",
       "16      0.652514\n",
       "17      0.099024\n",
       "18      0.055800\n",
       "19      0.167238\n",
       "20      0.056128\n",
       "21      0.073346\n",
       "22      0.040896\n",
       "23      0.046719\n",
       "24      0.066602\n",
       "25      0.015700\n",
       "26      0.018788\n",
       "27      0.099245\n",
       "28      0.744404\n",
       "29      0.054567\n",
       "          ...   \n",
       "9970    0.025056\n",
       "9971    0.032513\n",
       "9972    0.059166\n",
       "9973    0.030145\n",
       "9974    0.146219\n",
       "9975    0.132243\n",
       "9976    0.061952\n",
       "9977    0.497093\n",
       "9978    0.154263\n",
       "9979    0.033800\n",
       "9980    0.041427\n",
       "9981    0.000079\n",
       "9982    0.071002\n",
       "9983    0.961150\n",
       "9984    0.017224\n",
       "9985    0.113003\n",
       "9986    0.040686\n",
       "9987    0.729384\n",
       "9988    0.025192\n",
       "9989    0.066657\n",
       "9990    0.025502\n",
       "9991    0.011763\n",
       "9992    0.007214\n",
       "9993    0.004737\n",
       "9994    0.044174\n",
       "9995    0.125944\n",
       "9996    0.199613\n",
       "9997    0.018891\n",
       "9998    0.218019\n",
       "9999    0.052486\n",
       "Name: tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_3, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model = 'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738'\n",
    "_class = 3\n",
    "test_performance_df['{}_{}'.format(_model, _class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1530641399913,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "yc8SWZbqMwA4",
    "outputId": "6e9399b8-ce22-42bb-c318-959bae73f6c0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for class 0 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.472880379306\n",
      "Auc for class 1 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: nan\n",
      "Auc for class 2 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.494346987625\n",
      "Auc for class 3 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.5094779166\n",
      "Auc for class 4 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.579115768006\n",
      "Auc for class 5 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.495869234756\n",
      "Auc for class 6 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.468048349118\n",
      "Auc for class 7 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.485770898896\n",
      "Auc for class 8 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.491489665173\n",
      "Auc for class 9 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.47350564638\n",
      "Auc for class 10 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.488175572414\n",
      "Auc for class 11 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.52613046651\n",
      "Auc for class 12 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.496119960142\n",
      "Auc for class 13 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: nan\n",
      "Auc for class 14 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: nan\n",
      "Auc for class 15 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: nan\n",
      "Auc for class 16 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.520060671101\n",
      "Auc for class 17 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.502598042781\n",
      "Auc for class 18 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.471809136308\n",
      "Auc for class 19 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.589720292223\n",
      "Auc for class 20 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.464268809982\n",
      "Auc for class 21 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.451838849883\n",
      "Auc for class 22 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.501252940388\n",
      "Auc for class 23 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.522887952293\n",
      "Auc for class 24 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.50126994171\n",
      "Auc for class 25 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.502592883032\n",
      "Auc for class 26 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.4976489476\n",
      "Auc for class 27 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.413984124197\n",
      "Auc for class 28 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: nan\n",
      "Auc for class 29 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.485232058639\n",
      "Auc for class 30 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.475149523707\n",
      "Auc for class 31 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.512695371032\n",
      "Auc for class 32 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738: 0.443107537688\n",
      "Auc for class 0 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.473124962683\n",
      "Auc for class 1 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: nan\n",
      "Auc for class 2 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.502436065161\n",
      "Auc for class 3 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.497505395972\n",
      "Auc for class 4 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.533997183665\n",
      "Auc for class 5 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.516225645878\n",
      "Auc for class 6 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.479381557424\n",
      "Auc for class 7 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.503250547509\n",
      "Auc for class 8 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.501472866374\n",
      "Auc for class 9 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.511796004417\n",
      "Auc for class 10 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.472370750781\n",
      "Auc for class 11 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.503774777488\n",
      "Auc for class 12 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.482292660736\n",
      "Auc for class 13 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: nan\n",
      "Auc for class 14 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: nan\n",
      "Auc for class 15 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: nan\n",
      "Auc for class 16 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.509781244505\n",
      "Auc for class 17 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.511501561927\n",
      "Auc for class 18 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.466850476392\n",
      "Auc for class 19 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.616544907291\n",
      "Auc for class 20 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.517680398972\n",
      "Auc for class 21 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.48543965229\n",
      "Auc for class 22 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.498092928991\n",
      "Auc for class 23 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.527383088967\n",
      "Auc for class 24 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.516476102053\n",
      "Auc for class 25 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.498915515\n",
      "Auc for class 26 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.498317975812\n",
      "Auc for class 27 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.439794843499\n",
      "Auc for class 28 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: nan\n",
      "Auc for class 29 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.509969175195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nthain/Documents/repos/conversationai-models/model_evaluation/.venv/lib/python2.7/site-packages/sklearn/metrics/ranking.py:571: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for class 30 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.493638808206\n",
      "Auc for class 31 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.508299713945\n",
      "Auc for class 32 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132748: 0.457780904523\n",
      "Auc for class 0 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.496740926496\n",
      "Auc for class 1 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: nan\n",
      "Auc for class 2 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.499153608357\n",
      "Auc for class 3 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.499355443456\n",
      "Auc for class 4 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.519405656255\n",
      "Auc for class 5 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.510566062676\n",
      "Auc for class 6 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.480932677982\n",
      "Auc for class 7 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.492101760004\n",
      "Auc for class 8 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.521062880598\n",
      "Auc for class 9 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.46758254629\n",
      "Auc for class 10 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.475540747064\n",
      "Auc for class 11 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.540092938467\n",
      "Auc for class 12 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.486065994621\n",
      "Auc for class 13 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: nan\n",
      "Auc for class 14 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: nan\n",
      "Auc for class 15 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: nan\n",
      "Auc for class 16 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.488949553253\n",
      "Auc for class 17 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.512517147563\n",
      "Auc for class 18 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.480352770023\n",
      "Auc for class 19 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.524139214683\n",
      "Auc for class 20 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.531170784555\n",
      "Auc for class 21 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.486539618857\n",
      "Auc for class 22 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.493480481944\n",
      "Auc for class 23 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.493649014345\n",
      "Auc for class 24 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.519584546531\n",
      "Auc for class 25 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.502616827295\n",
      "Auc for class 26 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.499241317853\n",
      "Auc for class 27 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.527983296549\n",
      "Auc for class 28 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: nan\n",
      "Auc for class 29 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.513514238074\n",
      "Auc for class 30 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.505267708646\n",
      "Auc for class 31 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.526942603747\n",
      "Auc for class 32 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132820: 0.416369849246\n",
      "Auc for class 0 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.492310370551\n",
      "Auc for class 1 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: nan\n",
      "Auc for class 2 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.510422808191\n",
      "Auc for class 3 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.497258969647\n",
      "Auc for class 4 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.533468253803\n",
      "Auc for class 5 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.51988275004\n",
      "Auc for class 6 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.446890074912\n",
      "Auc for class 7 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.470106311844\n",
      "Auc for class 8 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.480683362454\n",
      "Auc for class 9 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.519891680117\n",
      "Auc for class 10 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.498969861354\n",
      "Auc for class 11 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.49575049304\n",
      "Auc for class 12 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.496308597575\n",
      "Auc for class 13 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: nan\n",
      "Auc for class 14 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: nan\n",
      "Auc for class 15 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: nan\n",
      "Auc for class 16 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.497497468669\n",
      "Auc for class 17 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.498361194233\n",
      "Auc for class 18 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.454219503411\n",
      "Auc for class 19 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.554294558911\n",
      "Auc for class 20 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.510198929845\n",
      "Auc for class 21 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.443848211301\n",
      "Auc for class 22 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.511251516464\n",
      "Auc for class 23 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.527593056506\n",
      "Auc for class 24 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.517610635095\n",
      "Auc for class 25 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.507171714086\n",
      "Auc for class 26 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.494850664384\n",
      "Auc for class 27 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.433402513042\n",
      "Auc for class 28 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: nan\n",
      "Auc for class 29 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.529500137723\n",
      "Auc for class 30 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.485269677036\n",
      "Auc for class 31 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.513662670014\n",
      "Auc for class 32 model tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132828: 0.429722613065\n"
     ]
    }
   ],
   "source": [
    "auc_list = []\n",
    "for _model in MODEL_NAMES:\n",
    "    for _class in CLASS_NAMES:\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(\n",
    "            test_performance_df['label'] == _class,\n",
    "            test_performance_df['{}_{}'.format(_model, _class)])\n",
    "        _auc = metrics.auc(fpr, tpr)\n",
    "        auc_list.append(_auc)\n",
    "        print ('Auc for class {} model {}: {}'.format(_class, _model, _auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for _model in MODEL_NAMES:\n",
    "    for _class in CLASS_NAMES:\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(\n",
    "            test_performance_df['label'] == _class,\n",
    "            test_performance_df['{}_{}'.format(_model, _class)])\n",
    "        _auc = metrics.auc(fpr, tpr)\n",
    "        auc_list.append(_auc)\n",
    "        print ('Auc for class {} model {}: {}'.format(_class, _model, _auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_class(df, model_name, class_names):\n",
    "    model_class_names = ['{}_{}'.format(model_name, class_name) for class_name in class_names]\n",
    "    sub_df = df[model_class_names]\n",
    "    df['{}_max'.format(model_name)] = sub_df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = 'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738'\n",
    "find_best_class(test_performance_df, _model, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "1       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "2       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "3       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "4       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "5       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "6       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "7       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "8       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9       tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "10      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "11      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "12      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "13      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "14      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "15      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "16      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "17      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "18      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "19      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "20      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "21      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "22      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "23      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "24      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "25      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "26      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "27      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "28      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "29      tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "                              ...                        \n",
       "9970    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9971    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9972    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9973    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9974    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9975    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9976    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9977    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9978    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9979    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9980    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9981    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9982    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9983    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9984    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9985    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9986    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9987    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9988    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9989    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9990    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9991    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9992    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9993    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9994    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9995    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9996    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9997    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9998    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "9999    tf_trainer_tf_gru_attention_multiclass_biosbia...\n",
       "Name: tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190306_132738_max, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_df['{}_max'.format(_model)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTrKsfIcxoBh"
   },
   "source": [
    "## Unintended Bias Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3ZJSKY8FHFH"
   },
   "source": [
    "### Data Format\n",
    "At this point, our bias data is in DataFrame df, with columns:\n",
    "\n",
    "*   label: True if the comment is Toxic, False otherwise.\n",
    "*   < model name >: One column per model, cells contain the score from that model.\n",
    "*   < subgroup >: One column per identity, True if the comment mentions this identity.\n",
    "\n",
    "You can run the analysis below on any data in this format. Subgroup labels can be \n",
    "generated via words in the text as done above, or come from human labels if you have them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'male'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d94e49a61360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midentity_terms_civil_included\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_term\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_fn_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity_terms_civil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bias_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_term\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'keeping {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0midentity_terms_civil_included\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nthain/Documents/repos/conversationai-models/model_evaluation/.venv/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nthain/Documents/repos/conversationai-models/model_evaluation/.venv/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nthain/Documents/repos/conversationai-models/model_evaluation/.venv/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nthain/Documents/repos/conversationai-models/model_evaluation/.venv/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nthain/Documents/repos/conversationai-models/model_evaluation/.venv/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'male'"
     ]
    }
   ],
   "source": [
    "identity_terms_civil_included = []\n",
    "for _term in input_fn_example.identity_terms_civil:\n",
    "    if sum(test_bias_df[_term]) >= 20:\n",
    "        print ('keeping {}'.format(_term))\n",
    "        identity_terms_civil_included.append(_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bias_df['model_1'] = test_bias_df['tf_gru_attention_civil:v_20181109_164318']\n",
    "test_bias_df['model_2'] = test_bias_df['tf_gru_attention_civil:v_20181109_164403']\n",
    "test_bias_df['model_3'] = test_bias_df['tf_gru_attention_civil:v_20181109_164535']\n",
    "test_bias_df['model_4'] = test_bias_df['tf_gru_attention_civil:v_20181109_164630']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['model_1', 'model_2', 'model_3', 'model_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_metrics = model_bias_analysis.compute_bias_metrics_for_models(test_bias_df, identity_terms_civil_included, MODEL_NAMES, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_analysis.plot_auc_heatmap(bias_metrics, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_analysis.plot_aeg_heatmap(bias_metrics, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "jigsaw-evaluation-pipeline.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "models_eval",
   "language": "python",
   "name": "models_eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
